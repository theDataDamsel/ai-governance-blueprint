# AI Governance Blueprint

Practical frameworks, policies, and templates for AI governance and model risk in enterprises.  
Focused on regulated, risk sensitive environments rather than lab demos.

## Why this repo exists

Most AI governance material is either:

- hand wavy ethics slides, or  
- deeply technical model docs nobody outside the data team reads.

This repo is meant to sit in the middle:

- concrete enough that data, IT and risk teams can actually use it  
- structured enough that executives and regulators can understand it

## What you will find here

Planned contents:

- **Governance operating model**
  - Roles and responsibilities for an AI Center of Excellence
  - RACI examples across business, data, IT, legal, risk, and audit
- **Policy and standards templates**
  - AI use policy outline
  - Model risk standard for ML and GenAI
  - Data usage, retention, and PII handling guidelines
- **Control libraries**
  - Example control set for traditional ML
  - Additional controls for GenAI and LLM usage
  - Mapping to three lines of defence in regulated environments
- **Process blueprints**
  - Model approval workflow
  - Exception handling and emergency rollback
  - Periodic review and revalidation
- **Assessment tools**
  - AI governance maturity checklist
  - CoE readiness assessment
  - Use case risk rating framework

Initially these will be Markdown documents and simple templates. Over time they can become questionnaires, checklists or small tools.

## Who this is for

- Organisations in **regulated industries** (financial services, healthcare, public sector, energy, utilities)
- AI / data leaders who need to prove to risk, legal, and regulators that AI is under control
- CoE and GenAI programme leads who want a starting point rather than a blank page
- Internal audit, compliance, and risk teams who need to review AI programmes

## How to use this repo

- Steal the templates and adapt them to your organisation
- Use the operating model and RACI examples as a starting point for your CoE design
- Take the control libraries and map them to your existing risk framework
- Use the assessment tools as input to board updates or strategic planning

This is not meant to be “the one true way”. It is a pragmatic starting point that reflects how AI actually gets scrutinised in real organisations.

## Roadmap

Short term:

- Add a basic AI governance operating model and role descriptions
- Publish a draft AI use policy skeleton
- Add a model risk and GenAI specific control checklist

Medium term:

- Extend the assessment tools into simple, repeatable questionnaires
- Add worked examples for a couple of common use cases (eg RAG assistant, decision support model)

Longer term:

- Link this governance blueprint to concrete implementation examples in other repos (RAG templates, GenAI cost monitoring, CoE Lead GPT)
